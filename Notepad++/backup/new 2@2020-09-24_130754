关于我

我能够做什么？
日常使用python编写脚本，熟练使用到的库包括：
- requests 目标网页请求,根据请求方法分别使用requests.get() requests.post();
- json 若目标网页返回字符串类型的json格式，使用json库把字符串装换字典数据类型 json.loads();
- bs4 若目标网页返回html,使用bs4进行提取数据 bs4.BeautifulSoup();
- MySQLdb 作为python操控sql桥梁，使用mysql存储数据；
- appium&&selenium 若目标反爬虫机制等级较高或只有手机客户端，使用appium或selenium进行数据爬取

日常最主要使用windows作为生产工具，choco作为软件管理；同时处于迁移linux系统阶段，熟练bash命令（aptget,chown,chmod,grep,useradd,userdelete,whereis)

我做过什么项目？
参加过一个业余公众号的运营：
情况：公众号利用海外代购业务作为营收，但由于缺乏热销商品类别及价格的数据，无法定位到用户需求；同时也有微商，淘宝其他渠道供应商进行竞价。
目标：在网上搜索3个主要以德国代购的网站

方案：爬取每个网站的浏览量、商品名称、作用以及价格，每个商品类别以浏览量筛选出top10商品拿到淘宝进行进行竞价提供到项目内部做参考

结果：最终爬取top10的商品以及与其他渠道的同类商品竞价的价格在公众号宣传



本人17年取得大学本科学历，东莞本地人，目前是互联网客服专席，处理日常互联网客诉工单。 于18年1月从事家宽售后数据统筹工作，以有2年工作经验，日常汇总数据与统筹指标，负责规范售后客诉工单流程图，拥有良好的沟通技巧及逻辑思维，对数据敏感细心，善于应变。项目结束后，期间参与拼多多售后客诉处理与赔付结算运营工作，并参与运营公众号，负责爬取多个国内代购网站的商品浏览量，提取每个浏览量为 TOP3 的商品到淘宝查看价格和月销量，选取 TOP5 的商品提供给团队做内部决策。日常业余时间喜欢学习办公软件工具(data crawling,markdown, bash , git .ect),关注最新科技行业动态。